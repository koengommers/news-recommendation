# @package _global_
defaults:
  - /tokenizer: bert

model:
  _target_: models.NRMS.NRMS
  num_attention_heads: 16

news_encoder:
  _target_: models.modules.bert.news_encoder.NewsEncoder
  pretrained_model_name: bert-base-uncased
  pooling_method: attention
  num_hidden_layers: 8
  finetune_n_last_layers: 2

features:
  - title
